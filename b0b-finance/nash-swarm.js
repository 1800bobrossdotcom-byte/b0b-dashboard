#!/usr/bin/env node
/**
 * ğŸ§  NASH SWARM - Cooperative Multi-Agent Trading System
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * 
 * Inspired by John Nash's game theory:
 * - Nash Equilibrium: No agent can improve by changing strategy alone
 * - Nash Bargaining: Cooperative solution maximizing joint utility
 * - Coalitional Games: Agents form coalitions for mutual benefit
 * 
 * Philosophy:
 * - Beyond PvP: Agents cooperate for collective wealth
 * - Mutual Respect: Each agent's contribution is valued
 * - Novel Iteration: Learn from each trade cycle
 * - Asymptotically Ideal: Converge toward optimal cooperation
 * 
 * Sources:
 * - LLM-TradeBot: 17-agent collaborative framework
 * - freqtrade: Battle-tested patterns
 * - hummingbot: Market making strategies
 * - kalshi-ai-trading-bot: Multi-agent decision engine
 * - Nash's "Ideal Money" concept
 * 
 * Usage:
 *   node nash-swarm.js council <market>   - Convene agent council
 *   node nash-swarm.js cooperate          - Run cooperative trading
 *   node nash-swarm.js equilibrium        - Find Nash equilibrium
 */

const EventEmitter = require('events');
const fs = require('fs');
const path = require('path');

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// NASH GAME THEORY CONSTANTS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const NASH = {
  // Bargaining weights (Nash Bargaining Solution)
  THREAT_POINT: 0,  // What each agent gets if no cooperation
  
  // Coalition parameters
  MIN_COALITION_SIZE: 2,
  MAX_COALITION_SIZE: 5,
  
  // Convergence parameters
  EQUILIBRIUM_THRESHOLD: 0.001,
  MAX_ITERATIONS: 100,
  LEARNING_RATE: 0.1,
  
  // Cooperative surplus sharing (Shapley-like)
  CONTRIBUTION_WEIGHT: 0.4,
  RISK_WEIGHT: 0.3,
  ACCURACY_WEIGHT: 0.3,
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// AGENT ROLES IN THE SWARM (from LLM-TradeBot + Nash)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const AGENT_ROLES = {
  // Data Layer
  SENTINEL: { name: 'Sentinel', role: 'Market Watcher', layer: 'data' },
  DATASYNC: { name: 'DataSync', role: 'Data Aggregator', layer: 'data' },
  
  // Analysis Layer  
  BULL: { name: 'Bull', role: 'Optimist Analyst', layer: 'analysis' },
  BEAR: { name: 'Bear', role: 'Pessimist Analyst', layer: 'analysis' },
  QUANT: { name: 'Quant', role: 'Statistical Analysis', layer: 'analysis' },
  
  // Decision Layer
  ARBITER: { name: 'Arbiter', role: 'Nash Equilibrium Finder', layer: 'decision' },
  COUNCIL: { name: 'Council', role: 'Cooperative Voting', layer: 'decision' },
  
  // Execution Layer
  EXECUTOR: { name: 'Executor', role: 'Trade Execution', layer: 'execution' },
  RISK: { name: 'Risk', role: 'Risk Veto Power', layer: 'execution' },
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// BASE COOPERATIVE AGENT
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class CooperativeAgent extends EventEmitter {
  constructor(role) {
    super();
    this.id = `agent_${role.name.toLowerCase()}_${Date.now()}`;
    this.role = role;
    this.beliefs = {};        // What this agent believes
    this.strategy = null;     // Current strategy
    this.utility = 0;         // Accumulated utility
    this.reputation = 1.0;    // Trust score (0-1)
    this.history = [];        // Past actions and outcomes
  }

  log(msg) {
    const ts = new Date().toISOString().split('T')[1].split('.')[0];
    console.log(`[${ts}] ğŸ¤– ${this.role.name}: ${msg}`);
  }

  // Update beliefs based on new information
  updateBeliefs(newInfo) {
    // Bayesian-like update
    for (const [key, value] of Object.entries(newInfo)) {
      if (this.beliefs[key]) {
        // Weighted average with existing belief
        this.beliefs[key] = this.beliefs[key] * (1 - NASH.LEARNING_RATE) + 
                           value * NASH.LEARNING_RATE;
      } else {
        this.beliefs[key] = value;
      }
    }
  }

  // Calculate contribution to coalition (Shapley value concept)
  calculateContribution(coalition, outcome) {
    // Simplified Shapley: how much value did this agent add?
    const withMe = outcome.totalUtility;
    const withoutMe = outcome.utilityWithout?.[this.id] || outcome.totalUtility * 0.8;
    return withMe - withoutMe;
  }

  // Update reputation based on outcome
  updateReputation(predicted, actual) {
    const accuracy = 1 - Math.abs(predicted - actual);
    this.reputation = this.reputation * 0.9 + accuracy * 0.1;
    this.reputation = Math.max(0.1, Math.min(1.0, this.reputation));
  }

  // Propose action (to be overridden)
  async propose(context) {
    throw new Error('Subclass must implement propose()');
  }

  // Vote on another agent's proposal (cooperative)
  async vote(proposal) {
    // By default, vote based on alignment with own beliefs
    const alignment = this.calculateAlignment(proposal);
    return {
      agentId: this.id,
      vote: alignment > 0.5 ? 'SUPPORT' : 'OPPOSE',
      confidence: Math.abs(alignment - 0.5) * 2,
      reason: alignment > 0.5 ? 'Aligned with my analysis' : 'Conflicts with my analysis',
    };
  }

  calculateAlignment(proposal) {
    // How much does this proposal align with my beliefs?
    let alignment = 0.5;
    if (this.beliefs.direction && proposal.direction) {
      alignment = this.beliefs.direction === proposal.direction ? 0.8 : 0.2;
    }
    return alignment;
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// SPECIALIZED AGENTS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class BullAgent extends CooperativeAgent {
  constructor() {
    super(AGENT_ROLES.BULL);
    this.bias = 0.6;  // Optimistic bias
  }

  async propose(context) {
    this.log(`Analyzing bullish case for ${context.market?.question?.slice(0, 30) || 'market'}...`);
    
    const price = context.currentPrice || 0.5;
    const momentum = context.priceChange24h || 0;
    
    // Bullish analysis
    const bullScore = (
      (price < 0.7 ? 0.3 : 0) +           // Undervalued
      (momentum > 0 ? 0.3 : 0) +           // Positive momentum
      (context.volume24h > 10000 ? 0.2 : 0) + // High volume
      this.bias * 0.2                      // Natural bias
    );

    this.beliefs = {
      direction: 'YES',
      confidence: bullScore,
      thesis: `Bullish case: Price ${price.toFixed(2)} with ${momentum > 0 ? 'positive' : 'negative'} momentum`,
    };

    return {
      agentId: this.id,
      direction: 'YES',
      confidence: bullScore,
      suggestedSize: bullScore * 100,  // $0-100 based on confidence
      thesis: this.beliefs.thesis,
    };
  }
}

class BearAgent extends CooperativeAgent {
  constructor() {
    super(AGENT_ROLES.BEAR);
    this.bias = 0.6;  // Pessimistic bias
  }

  async propose(context) {
    this.log(`Analyzing bearish case for ${context.market?.question?.slice(0, 30) || 'market'}...`);
    
    const price = context.currentPrice || 0.5;
    const momentum = context.priceChange24h || 0;
    
    // Bearish analysis
    const bearScore = (
      (price > 0.3 ? 0.3 : 0) +           // Overvalued
      (momentum < 0 ? 0.3 : 0) +           // Negative momentum
      (context.volatility > 0.1 ? 0.2 : 0) + // High volatility (uncertain)
      this.bias * 0.2                      // Natural bias
    );

    this.beliefs = {
      direction: 'NO',
      confidence: bearScore,
      thesis: `Bearish case: Price ${price.toFixed(2)} with risk of reversal`,
    };

    return {
      agentId: this.id,
      direction: 'NO',
      confidence: bearScore,
      suggestedSize: bearScore * 100,
      thesis: this.beliefs.thesis,
    };
  }
}

class QuantAgent extends CooperativeAgent {
  constructor() {
    super(AGENT_ROLES.QUANT);
  }

  async propose(context) {
    this.log(`Running quantitative analysis...`);
    
    const price = context.currentPrice || 0.5;
    const spread = context.spread || 0.05;
    const liquidity = context.liquidity || 0;
    
    // Statistical edge calculation
    const expectedValue = this.calculateExpectedValue(context);
    const kellyFraction = this.kellyOptimal(context);
    
    this.beliefs = {
      expectedValue,
      kellyFraction,
      edge: expectedValue - price,
    };

    const direction = this.beliefs.edge > 0 ? 'YES' : this.beliefs.edge < 0 ? 'NO' : null;

    return {
      agentId: this.id,
      direction,
      confidence: Math.abs(this.beliefs.edge) * 2,
      suggestedSize: kellyFraction * 200,  // Max $200 with full Kelly
      thesis: `Quant: EV=${expectedValue.toFixed(3)}, Edge=${(this.beliefs.edge * 100).toFixed(1)}%`,
      metrics: this.beliefs,
    };
  }

  calculateExpectedValue(context) {
    // Simplified EV calculation
    const price = context.currentPrice || 0.5;
    // Add some noise to simulate estimation uncertainty
    return price + (Math.random() - 0.5) * 0.1;
  }

  kellyOptimal(context) {
    // Kelly Criterion: f* = (bp - q) / b
    // where b = odds, p = win probability, q = 1-p
    const price = context.currentPrice || 0.5;
    const b = (1 - price) / price;  // Odds
    const p = this.calculateExpectedValue(context);
    const q = 1 - p;
    
    const kelly = (b * p - q) / b;
    return Math.max(0, Math.min(0.25, kelly));  // Cap at 25% of bankroll
  }
}

class RiskAgent extends CooperativeAgent {
  constructor() {
    super(AGENT_ROLES.RISK);
    this.maxExposure = 500;
    this.maxSingleBet = 100;
  }

  async propose(context) {
    this.log(`Assessing risk parameters...`);
    
    const checks = {
      liquidityOk: (context.liquidity || 0) > 5000,
      spreadOk: (context.spread || 1) < 0.05,
      exposureOk: (context.currentExposure || 0) < this.maxExposure,
      volatilityOk: (context.volatility || 0) < 0.2,
    };

    const passedChecks = Object.values(checks).filter(Boolean).length;
    const riskScore = passedChecks / Object.keys(checks).length;

    this.beliefs = {
      riskScore,
      checks,
      maxAllowedSize: riskScore > 0.75 ? this.maxSingleBet : riskScore > 0.5 ? 50 : 0,
    };

    return {
      agentId: this.id,
      direction: null,  // Risk agent doesn't pick direction
      approved: passedChecks >= 3,
      maxSize: this.beliefs.maxAllowedSize,
      riskScore,
      checks,
      veto: passedChecks < 2,
      vetoReason: passedChecks < 2 ? `Only ${passedChecks}/4 safety checks passed` : null,
    };
  }

  // Risk agent has veto power
  async vote(proposal) {
    if (proposal.suggestedSize > this.beliefs.maxAllowedSize) {
      return {
        agentId: this.id,
        vote: 'VETO',
        confidence: 1.0,
        reason: `Size ${proposal.suggestedSize} exceeds max allowed ${this.beliefs.maxAllowedSize}`,
        adjustment: { maxSize: this.beliefs.maxAllowedSize },
      };
    }
    return {
      agentId: this.id,
      vote: 'APPROVE',
      confidence: this.beliefs.riskScore,
      reason: 'Within risk parameters',
    };
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// NASH ARBITER - Finds Cooperative Equilibrium
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class NashArbiter extends CooperativeAgent {
  constructor() {
    super(AGENT_ROLES.ARBITER);
  }

  /**
   * Nash Bargaining Solution
   * Maximize the product of utilities above threat point:
   * max Î (u_i - d_i) where d_i is the threat point
   */
  findNashBargainingSolution(proposals) {
    this.log('Finding Nash Bargaining Solution...');

    // Extract directions and confidences
    const yesVotes = proposals.filter(p => p.direction === 'YES');
    const noVotes = proposals.filter(p => p.direction === 'NO');
    
    // Weighted average by confidence and reputation
    const yesStrength = yesVotes.reduce((sum, p) => sum + p.confidence * (p.reputation || 1), 0);
    const noStrength = noVotes.reduce((sum, p) => sum + p.confidence * (p.reputation || 1), 0);
    
    const totalStrength = yesStrength + noStrength || 1;
    
    // Nash Bargaining: find point that maximizes joint utility
    const consensusDirection = yesStrength > noStrength ? 'YES' : 
                              noStrength > yesStrength ? 'NO' : null;
    
    // Consensus confidence is geometric mean (Nash product)
    const relevantVotes = consensusDirection === 'YES' ? yesVotes : noVotes;
    const consensusConfidence = relevantVotes.length > 0 ?
      Math.pow(
        relevantVotes.reduce((prod, p) => prod * (p.confidence + 0.01), 1),
        1 / relevantVotes.length
      ) : 0;

    // Size is weighted average, bounded by risk
    const avgSize = proposals
      .filter(p => p.suggestedSize > 0)
      .reduce((sum, p, _, arr) => sum + p.suggestedSize / arr.length, 0);

    return {
      direction: consensusDirection,
      confidence: consensusConfidence,
      consensusStrength: Math.abs(yesStrength - noStrength) / totalStrength,
      suggestedSize: Math.min(avgSize, 100),
      yesStrength,
      noStrength,
      method: 'Nash Bargaining Solution',
    };
  }

  /**
   * Find Nash Equilibrium through iterative best response
   * Each agent plays best response to others' strategies
   */
  async findNashEquilibrium(agents, context, maxIterations = NASH.MAX_ITERATIONS) {
    this.log('Searching for Nash Equilibrium...');

    let iteration = 0;
    let converged = false;
    let strategies = new Map();

    // Initialize strategies
    for (const agent of agents) {
      const proposal = await agent.propose(context);
      strategies.set(agent.id, proposal);
    }

    while (!converged && iteration < maxIterations) {
      iteration++;
      let maxChange = 0;

      for (const agent of agents) {
        const oldStrategy = strategies.get(agent.id);
        
        // Agent calculates best response to others
        const othersStrategies = [...strategies.entries()]
          .filter(([id]) => id !== agent.id)
          .map(([, s]) => s);
        
        // Update context with others' strategies
        const newContext = { ...context, othersStrategies };
        const newStrategy = await agent.propose(newContext);
        
        // Calculate change
        const change = Math.abs((newStrategy.confidence || 0) - (oldStrategy.confidence || 0));
        maxChange = Math.max(maxChange, change);
        
        strategies.set(agent.id, newStrategy);
      }

      converged = maxChange < NASH.EQUILIBRIUM_THRESHOLD;
    }

    this.log(`${converged ? 'Converged' : 'Max iterations reached'} after ${iteration} iterations`);

    return {
      converged,
      iterations: iteration,
      strategies: Object.fromEntries(strategies),
      equilibrium: this.findNashBargainingSolution([...strategies.values()]),
    };
  }

  async propose(context) {
    // Arbiter synthesizes all proposals
    const proposals = context.proposals || [];
    const solution = this.findNashBargainingSolution(proposals);
    
    return {
      agentId: this.id,
      ...solution,
      thesis: `Nash Equilibrium: ${solution.direction || 'HOLD'} with ${(solution.confidence * 100).toFixed(0)}% consensus`,
    };
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// COOPERATIVE COUNCIL - Democratic Decision Making
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class CooperativeCouncil {
  constructor() {
    this.agents = [
      new BullAgent(),
      new BearAgent(),
      new QuantAgent(),
      new RiskAgent(),
      new NashArbiter(),
    ];
    this.history = [];
  }

  log(msg) {
    console.log(`\nğŸ›ï¸  COUNCIL: ${msg}\n${'â•'.repeat(60)}`);
  }

  async convene(context) {
    this.log('Convening cooperative council...');

    // Phase 1: Each agent proposes
    const proposals = [];
    for (const agent of this.agents) {
      if (agent.role.name !== 'Arbiter') {
        const proposal = await agent.propose(context);
        proposals.push(proposal);
      }
    }

    // Phase 2: Voting (cooperative, not adversarial)
    const votes = [];
    for (const agent of this.agents) {
      for (const proposal of proposals) {
        if (proposal.agentId !== agent.id) {
          const vote = await agent.vote(proposal);
          votes.push({ voter: agent.id, proposal: proposal.agentId, ...vote });
        }
      }
    }

    // Check for vetoes
    const vetoes = votes.filter(v => v.vote === 'VETO');
    if (vetoes.length > 0) {
      this.log(`VETO by Risk Agent: ${vetoes[0].reason}`);
      return {
        decision: 'BLOCKED',
        reason: vetoes[0].reason,
        adjustment: vetoes[0].adjustment,
        proposals,
        votes,
      };
    }

    // Phase 3: Nash Arbiter synthesizes
    const arbiter = this.agents.find(a => a.role.name === 'Arbiter');
    const consensus = await arbiter.propose({ ...context, proposals });

    // Phase 4: Calculate cooperative surplus sharing
    const surplus = this.calculateSurplusSharing(proposals, consensus);

    const decision = {
      timestamp: new Date().toISOString(),
      decision: consensus.direction ? 'TRADE' : 'HOLD',
      direction: consensus.direction,
      confidence: consensus.confidence,
      size: Math.min(consensus.suggestedSize, context.maxSize || 100),
      consensus,
      proposals,
      votes,
      surplusSharing: surplus,
      method: 'Nash Cooperative Council',
    };

    this.history.push(decision);
    this.printDecision(decision);

    return decision;
  }

  calculateSurplusSharing(proposals, consensus) {
    // Simplified Shapley-like value calculation
    const total = proposals.reduce((sum, p) => sum + (p.confidence || 0), 0);
    
    return proposals.map(p => ({
      agentId: p.agentId,
      contribution: ((p.confidence || 0) / total) * 100,
      alignedWithConsensus: p.direction === consensus.direction,
    }));
  }

  printDecision(decision) {
    console.log('\n' + 'â•'.repeat(60));
    console.log('ğŸ›ï¸  COUNCIL DECISION');
    console.log('â•'.repeat(60));
    
    console.log(`\nğŸ“Š PROPOSALS:`);
    for (const p of decision.proposals) {
      const agent = this.agents.find(a => a.id === p.agentId);
      console.log(`   ${agent?.role.name || 'Unknown'}: ${p.direction || 'NEUTRAL'} @ ${(p.confidence * 100).toFixed(0)}%`);
      if (p.thesis) console.log(`      "${p.thesis}"`);
    }

    console.log(`\nğŸ—³ï¸  VOTES:`);
    const votesSummary = decision.votes.reduce((acc, v) => {
      acc[v.vote] = (acc[v.vote] || 0) + 1;
      return acc;
    }, {});
    console.log(`   SUPPORT: ${votesSummary.SUPPORT || 0} | OPPOSE: ${votesSummary.OPPOSE || 0} | APPROVE: ${votesSummary.APPROVE || 0}`);

    console.log(`\nğŸ¯ CONSENSUS (Nash Bargaining):`);
    console.log(`   Direction: ${decision.direction || 'HOLD'}`);
    console.log(`   Confidence: ${(decision.confidence * 100).toFixed(0)}%`);
    console.log(`   Size: $${decision.size?.toFixed(2) || 0}`);

    console.log(`\nğŸ’° SURPLUS SHARING:`);
    for (const s of decision.surplusSharing || []) {
      const aligned = s.alignedWithConsensus ? 'âœ“' : 'âœ—';
      console.log(`   ${aligned} ${s.agentId.split('_')[1]}: ${s.contribution.toFixed(1)}% contribution`);
    }

    console.log('\n' + 'â•'.repeat(60));
  }

  // Update all agents based on outcome
  async updateFromOutcome(outcome) {
    for (const agent of this.agents) {
      // Find agent's prediction
      const prediction = this.history[this.history.length - 1]?.proposals
        .find(p => p.agentId === agent.id);
      
      if (prediction && prediction.direction) {
        const predicted = prediction.direction === 'YES' ? prediction.confidence : 1 - prediction.confidence;
        const actual = outcome.result === 'YES' ? 1 : 0;
        agent.updateReputation(predicted, actual);
      }
    }
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// NASH SWARM - Main Orchestrator
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class NashSwarm {
  constructor() {
    this.council = new CooperativeCouncil();
    this.stateFile = path.join(__dirname, 'nash-swarm-state.json');
    this.state = this.loadState();
  }

  loadState() {
    try {
      if (fs.existsSync(this.stateFile)) {
        return JSON.parse(fs.readFileSync(this.stateFile, 'utf-8'));
      }
    } catch (e) {}
    return {
      totalTrades: 0,
      wins: 0,
      losses: 0,
      totalPnL: 0,
      agentReputations: {},
    };
  }

  saveState() {
    fs.writeFileSync(this.stateFile, JSON.stringify(this.state, null, 2));
  }

  log(msg) {
    console.log(`\nğŸ§  NASH SWARM: ${msg}\n${'â•'.repeat(60)}`);
  }

  async runCooperativeTrading(context) {
    this.log('Starting cooperative trading session...');

    // Convene council for decision
    const decision = await this.council.convene(context);

    if (decision.decision === 'TRADE' && decision.confidence > 0.5) {
      this.log(`EXECUTING: ${decision.direction} for $${decision.size.toFixed(2)}`);
      
      // Here would be actual trade execution
      this.state.totalTrades++;
      this.saveState();
      
      return { executed: true, ...decision };
    } else {
      this.log(`HOLDING: Insufficient consensus (${(decision.confidence * 100).toFixed(0)}%)`);
      return { executed: false, ...decision };
    }
  }

  printPhilosophy() {
    console.log(`
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ§  NASH SWARM PHILOSOPHY                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                              â•‘
â•‘  Beyond PvP â†’ Cooperative Game Theory                        â•‘
â•‘                                                              â•‘
â•‘  â€¢ Nash Equilibrium: No agent can profit by defecting       â•‘
â•‘  â€¢ Nash Bargaining: Maximize joint utility                   â•‘
â•‘  â€¢ Shapley Values: Fair contribution attribution            â•‘
â•‘  â€¢ Reputation: Trust earned through accuracy                 â•‘
â•‘                                                              â•‘
â•‘  "The best for the group comes when everyone in the         â•‘
â•‘   group does what's best for himself AND the group."        â•‘
â•‘                                        â€” John Nash           â•‘
â•‘                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
`);
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// CLI
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async function main() {
  const args = process.argv.slice(2);
  const command = args[0];

  const swarm = new NashSwarm();
  swarm.printPhilosophy();

  // Mock context for testing
  const mockContext = {
    market: { question: 'Will Trump deport 750k+ in 2025?' },
    currentPrice: 0.45,
    priceChange24h: 0.05,
    volume24h: 50000,
    liquidity: 25000,
    spread: 0.02,
    volatility: 0.08,
    currentExposure: 100,
    maxSize: 100,
  };

  switch (command) {
    case 'council':
      const query = args.slice(1).join(' ') || 'test market';
      await swarm.runCooperativeTrading({ ...mockContext, query });
      break;

    case 'cooperate':
      await swarm.runCooperativeTrading(mockContext);
      break;

    case 'equilibrium':
      const arbiter = new NashArbiter();
      const agents = [new BullAgent(), new BearAgent(), new QuantAgent()];
      const result = await arbiter.findNashEquilibrium(agents, mockContext);
      console.log('\nğŸ“Š NASH EQUILIBRIUM RESULT:');
      console.log(JSON.stringify(result.equilibrium, null, 2));
      break;

    default:
      console.log(`
ğŸ§  NASH SWARM - Cooperative Multi-Agent Trading
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Commands:
  council <market>    Convene agent council for decision
  cooperate           Run cooperative trading session
  equilibrium         Find Nash equilibrium

Philosophy:
  â€¢ Beyond PvP: Agents cooperate for collective wealth
  â€¢ Nash Bargaining: Maximize joint utility
  â€¢ Shapley Values: Fair contribution sharing
  â€¢ Convergence: Approach optimal cooperation

Agents:
  ğŸ‚ Bull     - Optimist analysis
  ğŸ» Bear     - Pessimist analysis  
  ğŸ“Š Quant    - Statistical edge
  âš ï¸  Risk     - Safety (veto power)
  âš–ï¸  Arbiter  - Nash equilibrium finder
`);
  }
}

// Export
module.exports = { NashSwarm, CooperativeCouncil, NashArbiter, NASH };

// Run
if (require.main === module) {
  main().catch(console.error);
}
